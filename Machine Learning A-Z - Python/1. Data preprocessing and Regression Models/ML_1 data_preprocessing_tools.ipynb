{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-oRijAoUwpp2Qlz-Kl3k6hNlodWQyf87","timestamp":1751197506580}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"37puETfgRzzg"},"source":["# Data Preprocessing Tools"]},{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["## Importing the libraries"]},{"cell_type":"code","source":["import numpy as np #to process arrays as inputs. \"as np\" to make a shortcut call in case we want to use numpy\n","import matplotlib.pyplot as plt #to plot charts. \".\" to use specific module pyplot and \"plt\" as shortcut\n","import pandas as pd #import data set and matrices. \"pd\" -> shortcut"],"metadata":{"id":"FpiFUbmvgwxt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","source":["dataset = pd.read_csv('Data.csv') #read data from csv file. It's a function from pandas\n","#Every dataset have features and dependant variables. Features -> Columns. Dependant variable -> what you want to predict (last column usually)\n","#NOTA -> caso os dados estejam separados por \";\" --> dataset = pd.read_csv('winequality-red.csv', delimiter=';')\n","\n","\n","#Matrice (with features and respective values) EX: Country, age, salary\n","X = dataset.iloc[:, :-1].values #locate indexes (iloc) - vai procurar os indices rows,col , retira e coloca em X\n","#: -> takes everything in the range. (All the rows)\n","#:-1 -> takes every column except the last one (which is the dependant variable vector)\n","\n","#Dependant Variable Vector (what you must predict) EX: Purchased (Yes or No)\n","Y = dataset.iloc[:, -1].values #will get all the rows of the last column\n","\n","#Outro exemplo para serparar dados de variaveis dependentes e variaveis independentes\n","#\n","#X = dataset.drop('quality', axis=1)\n","#y = dataset['quality']\n","#\n","#quality é a"],"metadata":{"id":"EhdP9qNnhgcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2yyf6TZSDJr4","executionInfo":{"status":"ok","timestamp":1751318160560,"user_tz":-60,"elapsed":12,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"94edeca9-b2ea-4ac4-effb-120cfdb44d44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5zI3p8MDOWr","executionInfo":{"status":"ok","timestamp":1751318160577,"user_tz":-60,"elapsed":15,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"c14e4581-25db-4e4c-ccfd-c2781e1bf16f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data"]},{"cell_type":"code","source":["#We don't want missing data. So we must handle them\n","#1. Ignore observation by deleting the whole row - not a problem if you have much data\n","#2. Replace missing data by the AVG of all the values in the column.\n","#sometimes people also do Median, Modal, etc. But AVG is the most used\n","\n","from sklearn.impute import SimpleImputer #library para data scientists. mt boa\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean') #create a new object of the SimpleImputer class. Não precisa de inputs\n","#deals missing values (np.nan) with the strategy mean (AVG)\n","#This just identifies the missing values, it doesn't actually replace them. For that - we do the fit method:\n","imputer.fit(X[:, 1:3]) #!!!only the numeric values!!!. no strings or booleans. We will only specify age and salary (numbers!) country no good.\n","#why 1:3? because we want the columns 1 and 2 (columns start counting in 0 and the upper bound isn't used by the function). Age and salary are\n","#1 and 2 so we will do 1:3\n","X[:, 1:3] = imputer.transform(X[:, 1:3]) #para transformar efetivamente. Como tem return das colunas transformadas, precisamos\n","#de as por no X novamente --> X[:, 1:3]\n","\n","#caso quisesse ver dados nulos -> # Identify missing data    --> print(dataset.isnull().sum())\n"],"metadata":{"id":"NO5Vxq19FnJf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OADWAynUJKcB","executionInfo":{"status":"ok","timestamp":1751318160614,"user_tz":-60,"elapsed":28,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"7343ad72-b5f4-4948-b029-040432d54fb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data"]},{"cell_type":"code","source":["#Transformar features categóricas em números.\n","#Exemplo - France, Spain, Germany? da Coluna Country. Ordem NAO INTERESSA, LOGO APLICAR ONE HOT ENCODING.\n","#1. One-Hot encoding -> Transformar a coluna Country em três diferentes (porque existem três países diferentes)\n","#Cria vetores binários para cada um desses paises. EX: France (1,0,0), Spain (0,1,0) e Germany (0,0,1).\n","#Assim nao ha\n","\n","#MT IMP - Um nome não é categorical data. Porquê? POrque é único. Após aplicar-se o One-Hot Encoding, iria fazer arrays enormes.\n","#Alem de tambem nao servir para qualquer tipo de predição..."],"metadata":{"id":"L6RertNQOL8Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","source":["#PARA APLICACOES -> BASTA ALTERAR A COLUNA REFERIDA NO OBJETO DE COLUMN TRANSFER (O 0) PELA COLUNA QUE QUEREMOS\n","\n","#Country é uma variavel independente. Vamos mexer nisso\n","#Duas classes\n","from sklearn.compose import ColumnTransformer #transformar colunas\n","from sklearn.preprocessing import OneHotEncoder #para a tecnica one hot encoder\n","\n","#Criar objetos\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","#queremos transformar com o onehotencoder na coluna 0 (Country). Remainder sao as restantes. Queremos manter portanto\n","#fica passthrough\n","#Solucao alternativa - caso quisesse escrever especificamente as colunas em vez dos seus indices:\n","#categorical_features = ['Sex', 'Embarked', 'Pclass']\n","# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_features)], remainder='passthrough')\n","\n","#aplicar o fit e transformar o array das variaveis independentes\n","X = np.array(ct.fit_transform(X)) #np.array para obrigarmos a que o output da transformacao seja um array\n"],"metadata":{"id":"q5iGHQ04O3eF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3UcvDcAR4bl","executionInfo":{"status":"ok","timestamp":1751318160630,"user_tz":-60,"elapsed":10,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"8dcf785e-3120-48d5-821f-7825a9d23167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable"]},{"cell_type":"code","source":["# APLICAR A VARIAVEIS CATEGORICAS QUANDO A ORDEM INTERESSA\n","#EXEMPLO - TAMANHOS DE ROUPA\n","#Para aplicar -> definir Y como a coluna à qual se quer aplicar. Podes ver o caso em baixo caso queiras que ele procure a coluna por nomenclatura\n","#ou, por exemplo -> coluna 3: X[:, 2] = le.fit_transform(X[:, 2])\n","#\n","#A variavel dependente é Yes ou No portanto é categórica\n","#Vamos fazer para ficar 0 ou 1 (No or Yes)\n","#Binary Outcome\n","\n","\n","from sklearn.preprocessing import LabelEncoder #encoder\n","le = LabelEncoder() #object. Não precisamos de dar inputs porque é só uma coluna\n","Y = le.fit_transform(Y)\n","\n","#NOTA ALT: Caso quisesse selecionar uma coluna que ja sei que é a variavel dependente (e nao é a última)\n","#le = LabelEncoder()\n","#y = le.fit_transform(dataset['Survived'])"],"metadata":{"id":"CCh1Ai8BSKeW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NijsE1LTSndm","executionInfo":{"status":"ok","timestamp":1751318160677,"user_tz":-60,"elapsed":33,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"a9fff00f-1c65-422b-f88f-e2e935435bb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"qb_vcgm3qZKW"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","source":["#Treinar o modelo em existing data sets\n","#Avaliar o output do modelo correlacionando com data test\n","#X train, X test ; Y train, Y test. Quatro\n","from sklearn.model_selection import train_test_split #funcao para split de train e test\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n","#variaveis dependentes (X), variaveis independentes (Y), 20% das observacoes vao para o teste (escolhidas randomly)\n","#random_state = 1 fica fixed portanto nao fica random\n"],"metadata":{"id":"Hak6fWuoiOYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train) #8 observacoes pq metemos test size = 0.2 e temos 10 obs no total"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxlhP7eYojgO","executionInfo":{"status":"ok","timestamp":1751318160679,"user_tz":-60,"elapsed":24,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"1dff8de2-f440-47c6-c0d2-4201e8e06102"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYFKYobDojmM","executionInfo":{"status":"ok","timestamp":1751318160680,"user_tz":-60,"elapsed":18,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"83b3d460-e254-45bd-9f90-094e84d30823"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"code","source":["print(Y_train) #nota importante - correspondem aos customers de cima (X_train)!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1AODnKzojr7","executionInfo":{"status":"ok","timestamp":1751318160698,"user_tz":-60,"elapsed":18,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"8cc99678-608d-4b28-8759-702a3b2bf311"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1]\n"]}]},{"cell_type":"code","source":["print(Y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JiZ1q2Esojxc","executionInfo":{"status":"ok","timestamp":1751318160700,"user_tz":-60,"elapsed":11,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"c5e718e2-d55d-45c6-ef4a-83eb5b460a60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TpGqbS4TqkIR"},"source":["## Feature Scaling"]},{"cell_type":"code","source":["#PARA OUTRAS APLICACOES -> PODE-SE APLICAR A TUDO. TIRAR AS COLUNAS AÍ. EX: ANN.\n","\n","#Tem que ser depois de diferenciar o training set e o test set. Nem todos fazem assim\n","#Mas deve-se ao facto de:\n","# Test set tem que ser um novo brand new set (new observations). Como feature scaling implica mexer nos dados\n","# Prevents information leakage on the test set (which should not happen until the training is done).\n","\n","#They must all take values in the same scale. No characteristic should override the others.\n","\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler() #object do standard scaler\n","#standard scaler aplica-se mesmo aos valores dummy (array dos países, por exemplo)? Não. Não é preciso. Porque eles já estão entre 0 e 1\n","\n","#lets fit into train set. We'll only take the columns of age and salary because country is an array one-hot encoded\n","#Olhando para cima, [0,0,1,38,52000] --> queremos a 3 e 4\n","X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n","#O fit calcula media e standard deviation de cada coluna\n","#transform vai aplicar a formula.\n","#fit_transform faz os dois ao mesmo tempo\n","\n","#Os scalers têm que ser iguais no training set e no test set\n","#Porquê? porque queremos a mesma aplicação entre dados.\n","X_test[:, 3:] = sc.fit_transform(X_test[:, 3:])\n","\n","#NOTA IMP - na logistic regression tirámos a selecao das colunas [:, 3:] em ambos os lados. Provavelmente dá para fazer igual\n","#em todo o lado\n"],"metadata":{"id":"RI8zqaakfpof"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58IctoHNsJ1T","executionInfo":{"status":"ok","timestamp":1751318160710,"user_tz":-60,"elapsed":8,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"cd94c2f5-90ba-47d5-9784-a516644b51bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n"," [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n"," [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n"," [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n"," [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n"," [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n"," [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n"," [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"]}]},{"cell_type":"code","source":["print(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjoOz4B3sLQg","executionInfo":{"status":"ok","timestamp":1751318160727,"user_tz":-60,"elapsed":15,"user":{"displayName":"rsdelaunay","userId":"07959066024303116615"}},"outputId":"807dc84d-f2e6-4b4d-ff98-2cc9ec2f21b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 -1.0 -1.0]\n"," [1.0 0.0 0.0 1.0 1.0]]\n"]}]}]}